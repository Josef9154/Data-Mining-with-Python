{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joseph Rochelle\n",
    "## DSC 550 Data mining\n",
    "## Week 4 Assignment (Text: Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "#Setting Decimal point preference\n",
    "np.set_printoptions(precision =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day of Week</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Hello, how are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Today is a good day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>It's my birthday so it's a really special day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Today is neither a good day or a bad day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>I'm having a bad day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>There' s nothing special happening today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Today is a SUPER good day!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day of Week                                        comments\n",
       "0      Monday                             Hello, how are you?\n",
       "1     Tuesday                            Today is a good day!\n",
       "2   Wednesday  It's my birthday so it's a really special day!\n",
       "3    Thursday       Today is neither a good day or a bad day!\n",
       "4      Friday                           I'm having a bad day.\n",
       "5    Saturday       There' s nothing special happening today.\n",
       "6      Sunday                      Today is a SUPER good day!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading data frame\n",
    "DailyDf= pd.read_csv('DailyComments.csv')  \n",
    "DailyDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual Sentiment Analizer:**\n",
    "    \n",
    "The purpose of this section is to provide the reader with a means to count key words that are meaningful to the researcher. Based off the use cases, there may be a time where evaluating key words and phrases and providing meaning may be important. This section serves as a means to create a column for key words and counts then to summarize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = DailyDf['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "vectorized words\n",
      "\n",
      "['are', 'bad', 'birthday', 'day', 'good', 'happening', 'having', 'hello', 'how', 'is', 'it', 'my', 'neither', 'nothing', 'or', 'really', 'so', 'special', 'super', 'there', 'today', 'you']\n",
      "\n",
      "Identify Feature Words - Matrix View\n",
      "\n",
      "[[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 2 1 0 0 0 1 1 1 0 0 0 0]\n",
      " [0 1 0 2 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0]]\n",
      "\n",
      "                                             text  positive1  positive2  \\\n",
      "0                             Hello, how are you?          0          0   \n",
      "1                            Today is a good day!          1          0   \n",
      "2  It's my birthday so it's a really special day!          0          1   \n",
      "3       Today is neither a good day or a bad day!          1          0   \n",
      "4                           I'm having a bad day.          0          0   \n",
      "5       There' s nothing special happening today.          0          1   \n",
      "6                      Today is a SUPER good day!          1          0   \n",
      "\n",
      "   negative  TotScore  TotCount  \n",
      "0         0         0         0  \n",
      "1         0         1         1  \n",
      "2         0         1         1  \n",
      "3         1         0         2  \n",
      "4         1        -1         1  \n",
      "5         0         1         1  \n",
      "6         0         1         1  \n",
      "\n",
      "Overall Score:   3\n",
      "Overall Count:   7\n",
      "Positive Sentiment %: 0.43\n"
     ]
    }
   ],
   "source": [
    "#Vectorizing the words within the corpus, which is our text only comments.\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(\"\")\n",
    "print(\"vectorized words\")\n",
    "print(\"\")\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"\")\n",
    "print(\"Identify Feature Words - Matrix View\")\n",
    "print(\"\")\n",
    "print( X.toarray())\n",
    "\n",
    "\n",
    "#After turning the vectors into arrays we put it back into a data frame\n",
    "\n",
    "df = pd.DataFrame({'text' : corpus})\n",
    "\n",
    "#Check for positive words and negative words based off the schema established. I want to do linguistics connections like very bad super special later. \n",
    "#This methods counts the words in our text data frame, adding positive and negative columns. Then, calculated field column totallying.\n",
    "df['positive1'] = df.text.str.count('good')\n",
    "df['positive2']= df.text.str.count('special')\n",
    "df['negative'] = df.text.str.count('bad')\n",
    "df['TotScore'] = df.positive1 + df.positive2 - df.negative\n",
    "df['TotCount'] = df.positive1 + df.positive2 + df.negative\n",
    "\n",
    "print(\"\")\n",
    "print(df)\n",
    "\n",
    "# Printing the results in a data frame based off the scoring of sentiment analysis above\n",
    "Z = sum(df['TotScore'])\n",
    "Z1= sum(df['TotCount'])\n",
    "Z2 = Z/Z1\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Overall Score:  \",Z)\n",
    "print(\"Overall Count:  \",Z1)\n",
    "\n",
    "# The % of sentiment that was negative. \n",
    "#While the researcher does not have to use negative sentiment as the numerator to the total count of words as the denominator, this researcher sought to bring that option to the analysis. \n",
    "print(\"Positive Sentiment %:\"+\" {:.2f}\".format(Z2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With NLK Sentiment Intensity Analyzer:** \n",
    "\n",
    "The purpose of this section is to shift from creating a manual sentiment library of words to an analyzer with a corpus alreayd established. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences =DailyDf['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you?\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Today is a good day!\n",
      "compound: 0.4926, neg: 0.0, neu: 0.484, pos: 0.516, \n",
      "It's my birthday so it's a really special day!\n",
      "compound: 0.5497, neg: 0.0, neu: 0.664, pos: 0.336, \n",
      "Today is neither a good day or a bad day!\n",
      "compound: -0.735, neg: 0.508, neu: 0.492, pos: 0.0, \n",
      "I'm having a bad day.\n",
      "compound: -0.5423, neg: 0.538, neu: 0.462, pos: 0.0, \n",
      "There' s nothing special happening today.\n",
      "compound: -0.3089, neg: 0.361, neu: 0.639, pos: 0.0, \n",
      "Today is a SUPER good day!\n",
      "compound: 0.8327, neg: 0.0, neu: 0.277, pos: 0.723, \n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    ">>> for sentence in sentences:\n",
    "...     print(sentence)\n",
    "...     ss = sid.polarity_scores(sentence)\n",
    "...     for k in sorted(ss):\n",
    "...         print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "...     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples of how to complete sentiment analysis on Twitter comments:**\n",
    "\n",
    "The purpose of this section is to examine the sentiment as they relate to some trending comments from twitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "api = twitter.Api(consumer_key='5yVCXTUSc9YlNV8ZhKxa301PV',\n",
    "  consumer_secret='5WxPIFQptDTOrR2vO65lbajjlg6LwzhIFQ5vRr8q3Z9sau4NuY',\n",
    "    access_token_key='1245795441003974656-AXifRFL7o9MhyU6uT3tltrab1rY7Ga',\n",
    "    access_token_secret='GarNU7M6CMjGNemtRkXQyjivkNHrc7cQqQ9URbv2F0rI8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Status(ID=1308831501275009032, ScreenName=jemelehill, Created=Wed Sep 23 18:12:01 +0000 2020, Text='The state of Kentucky deemed the lives of Breonna Taylor’s neighbors to be worth more than her own. Let that sink in.'),\n",
       " Status(ID=1308838463282835457, ScreenName=YaraShahidi, Created=Wed Sep 23 18:39:41 +0000 2020, Text=\"What is most insulting is that the recommended charges aren't even in response to the MURDER of Breonna Taylor, but… https://t.co/KmFOC721JJ\"),\n",
       " Status(ID=1308843681668046848, ScreenName=ClintSmithIII, Created=Wed Sep 23 19:00:25 +0000 2020, Text=\"I'm thinking of all the ppl who knew Breonna Taylor before she became hashtag. The people who raised her, the peopl… https://t.co/ikWXAONzWg\"),\n",
       " Status(ID=1308952761925427201, ScreenName=mandeeeeee0, Created=Thu Sep 24 02:13:52 +0000 2020, Text='RT @sasquatchstacy: if you used \"arrest the killers of breonna taylor\" as a caption on a selfie post, you better be sending buckets of mone…'),\n",
       " Status(ID=1308952761807953920, ScreenName=12thmanmondo, Created=Thu Sep 24 02:13:52 +0000 2020, Text='RT @sethdunlap: Louisville Police now saying, “We’re going to arrest every single person who is here right now.”  There are thousands of pe…'),\n",
       " Status(ID=1308952761757769729, ScreenName=ItsJus_Smoov3, Created=Thu Sep 24 02:13:52 +0000 2020, Text='RT @RexChapman: Guys, never forget that Breonna Taylor’s killers were at the wrong house. \\n\\nThe wrong house.'),\n",
       " Status(ID=1308952761699053569, ScreenName=flo_resss, Created=Thu Sep 24 02:13:52 +0000 2020, Text='RT @mynameisjro: This country would rather deploy the National Guard on protestors than cement justice for Breonna Taylor. If you are wonde…'),\n",
       " Status(ID=1308952761648766977, ScreenName=RAIIDAPLUG, Created=Thu Sep 24 02:13:52 +0000 2020, Text='EVERYBODY went up for George Floyd !!! But when it comes to Breonna Taylor everybody on hush mode 🤬... this is sick… https://t.co/uRlWolTRiD'),\n",
       " Status(ID=1308952761627598848, ScreenName=E1JUNSBF, Created=Thu Sep 24 02:13:52 +0000 2020, Text=\"RT @ACH00MU: my platform isn't that big but i'm willing to raise awareness and use my voice for breonna taylor's case, here's the links whe…\"),\n",
       " Status(ID=1308952761619419138, ScreenName=EngWood3, Created=Thu Sep 24 02:13:52 +0000 2020, Text='RT @AttorneyCrump: How ironic and typical that the only charges brought in Breonna Taylor’s case were for shots fired into the apartment of…')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=api.GetSearch(term='Breonna Taylor', since=2016-11-21, count=10)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBreonnaTaylor_Tweets=pd.DataFrame (data=[tweet.text for tweet in tweets], columns = ['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTSentences= dfBreonnaTaylor_Tweets['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state of Kentucky deemed the lives of Breonna Taylor’s neighbors to be worth more than her own. Let that sink in.\n",
      "compound: 0.2263, neg: 0.0, neu: 0.917, pos: 0.083, \n",
      "What is most insulting is that the recommended charges aren't even in response to the MURDER of Breonna Taylor, but… https://t.co/KmFOC721JJ\n",
      "compound: -0.8814, neg: 0.37, neu: 0.57, pos: 0.06, \n",
      "I'm thinking of all the ppl who knew Breonna Taylor before she became hashtag. The people who raised her, the peopl… https://t.co/ikWXAONzWg\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "RT @sasquatchstacy: if you used \"arrest the killers of breonna taylor\" as a caption on a selfie post, you better be sending buckets of mone…\n",
      "compound: -0.5859, neg: 0.226, neu: 0.676, pos: 0.098, \n",
      "RT @sethdunlap: Louisville Police now saying, “We’re going to arrest every single person who is here right now.”  There are thousands of pe…\n",
      "compound: -0.34, neg: 0.098, neu: 0.902, pos: 0.0, \n",
      "RT @RexChapman: Guys, never forget that Breonna Taylor’s killers were at the wrong house. \n",
      "\n",
      "The wrong house.\n",
      "compound: -0.87, neg: 0.417, neu: 0.517, pos: 0.066, \n",
      "RT @mynameisjro: This country would rather deploy the National Guard on protestors than cement justice for Breonna Taylor. If you are wonde…\n",
      "compound: 0.5267, neg: 0.0, neu: 0.861, pos: 0.139, \n",
      "EVERYBODY went up for George Floyd !!! But when it comes to Breonna Taylor everybody on hush mode 🤬... this is sick… https://t.co/uRlWolTRiD\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "RT @ACH00MU: my platform isn't that big but i'm willing to raise awareness and use my voice for breonna taylor's case, here's the links whe…\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "RT @AttorneyCrump: How ironic and typical that the only charges brought in Breonna Taylor’s case were for shots fired into the apartment of…\n",
      "compound: -0.7351, neg: 0.265, neu: 0.735, pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    ">>> for sentence in BTSentences:\n",
    "...     print(sentence)\n",
    "...     ss = sid.polarity_scores(sentence)\n",
    "...     for k in sorted(ss):\n",
    "...         print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "...     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** \n",
    "\n",
    "As very much expected, there is a lot of social unrest toward Breonna Taylors death and sentiment here shows that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
